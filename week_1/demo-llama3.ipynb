{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "9Y0UUTVR-fEc"
      },
      "outputs": [],
      "source": [
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_text_splitters import MarkdownTextSplitter\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "from langchain_community.llms import Ollama\n",
        "\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "import tqdm\n",
        "import os\n",
        "\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4Y7EM_qO-fEe"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "#from langchain_community.document_loaders import WebBaseLoader\n",
        "\n",
        "loader = PyPDFLoader(\"docs/Sách Deep Learning cơ bản.pdf\")\n",
        "# loader = WebBaseLoader(\"https://docs.smith.langchain.com/user_guide\")\n",
        "\n",
        "pages = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rpFB-ghS-fEe",
        "outputId": "dac32847-a281-443c-e2cd-faabee78b58d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "227\n"
          ]
        }
      ],
      "source": [
        "print(len(pages))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zGos-08u-fEf"
      },
      "outputs": [],
      "source": [
        "\n",
        "text_splitter = MarkdownTextSplitter(\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=100,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "UZVnJL1q-fEf"
      },
      "outputs": [],
      "source": [
        "docs = text_splitter.split_documents(pages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "T2iqH7zp-fEf",
        "outputId": "c79a2db9-06d1-49a5-ac93-b4e46026d2f8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\thực tập doanh nghiệp\\venv\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
            "  warn_deprecated(\n",
            "d:\\thực tập doanh nghiệp\\venv\\lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from tqdm.autonotebook import tqdm, trange\n",
            "d:\\thực tập doanh nghiệp\\venv\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "model = \"keepitreal/vietnamese-sbert\"\n",
        "embeddings = HuggingFaceEmbeddings(model_name = model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r5V4ci5F-fEg"
      },
      "outputs": [],
      "source": [
        "vectorstore = FAISS.from_documents(docs, embeddings)\n",
        "vectorstore.save_local(\"faiss_index\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "EFIaCBG8-fEg"
      },
      "outputs": [],
      "source": [
        "vectorstore = FAISS.load_local(\"faiss_index\", embeddings, allow_dangerous_deserialization=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "hg6G2bg_-fEg",
        "outputId": "f8a23724-39a6-4ebe-9c9b-cf1903e51793"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'130 Chương 9. Giới thiệu keras và bài toán phân loại ảnh\\nĐể ý là label của data là số i là vector v kích thước 10*1 với vi+1=1và các giá trị khác bằng 0. So\\nvới quy ước về phần trăm ở trên thì one-hot encoding có ý nghĩa là ta chắc chắn 100% ảnh này là số 5.\\nGiờ ta có giá trị thật (label) dạng one-hot encoding giá trị dự đoán ở output layer sau hàm softmax\\nfunction cùng kích thước 10*1. Ta cần định nghĩa hàm loss function để đánh giá độ tốt của model.\\nMong muốn là a6gần 1 còn các giá trị a khác gần 0 vì như thế nghĩa là model dự đoán đúng được\\nảnh đầu vào là ảnh số 5. Ta định nghĩa loss function:\\nL=−10\\n∑\\ni=1yi∗log(ˆyi)'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "question = \"loss fuction\"\n",
        "docs = vectorstore.max_marginal_relevance_search(question,k=3)\n",
        "docs[0].page_content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "2ys9iMdC-fEh"
      },
      "outputs": [],
      "source": [
        "retriever = vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 10})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "eJaaNXm7-fEh"
      },
      "outputs": [],
      "source": [
        "llm = Ollama(model=\"llama3\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "-WSMCxU0-fEh",
        "outputId": "8bf87455-ae79-41ac-f46d-d4776690782d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input_variables=['context', 'question'] messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], template='\\nBạn là trợ lý cho các nhiệm vụ trả lời câu hỏi.\\nHãy trả lời câu hỏi dựa trên dữ liệu có trong đoạn ngữ cảnh\\nHãy trả lời không biết nêu không có thông tin tron đoạn ngữ cảnh\\n\\nđoạn ngữ cảnh: {context}\\n\\ncâu hỏi: {question}\\n\\ncâu trả lời:\\n'))]\n"
          ]
        }
      ],
      "source": [
        "prompt_text = \"\"\"\n",
        "Bạn là trợ lý cho các nhiệm vụ trả lời câu hỏi.\n",
        "Hãy trả lời câu hỏi dựa trên dữ liệu có trong đoạn ngữ cảnh\n",
        "Hãy trả lời không biết nêu không có thông tin tron đoạn ngữ cảnh\n",
        "\n",
        "đoạn ngữ cảnh: {context}\n",
        "\n",
        "câu hỏi: {question}\n",
        "\n",
        "câu trả lời:\n",
        "\"\"\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(prompt_text)\n",
        "print(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "6dBOPbkK-fEh"
      },
      "outputs": [],
      "source": [
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "\n",
        "rag_chain = (\n",
        "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "cuzW2OHz-fEi",
        "outputId": "eaa8f485-0f83-4ca4-91bb-d40d957f1cef"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'CNN (Convolutional Neural Network) is a type of artificial neural network that is primarily used for image and signal processing. The main characteristic of a CNN is the use of convolutional layers, which apply filters to small regions in an image, and pooling layers, which downsample the output of each filter.\\n\\nIn essence, CNNs are designed to take advantage of the spatial hierarchies present in images by using convolutional and pooling layers to extract features at multiple scales. This allows them to learn invariant representations of objects that can be used for tasks such as object detection, image classification, and segmentation.\\n\\nCNNs have been widely used in many applications, including computer vision, natural language processing, and audio processing.'"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "question = \"CNN là gì?\"\n",
        "rag_chain.invoke(question)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_response(input_text):\n",
        "    response = rag_chain.invoke(input_text)\n",
        "    return response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running on local URL:  http://127.0.0.1:7860\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gradio as gr\n",
        "\n",
        "\n",
        "iface = gr.Interface(generate_response, \n",
        "                     inputs=\"textbox\",\n",
        "                     outputs=\"textbox\",\n",
        "                     title=\"Chatbot about Deep learning\",\n",
        "                     description=\"Enter your message and the chatbot will respond accordingly.\")\n",
        "iface.launch()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
