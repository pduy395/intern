{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import MarkdownTextSplitter,RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "from langchain_community.llms import Ollama\n",
    "\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "import tqdm\n",
    "import os\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "#from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = PyPDFLoader(\"../data/AT_PersonalInformation_Intern.pdf\")\n",
    "# loader = WebBaseLoader(\"https://docs.smith.langchain.com/user_guide\")\n",
    "\n",
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# text_splitter = MarkdownTextSplitter(\n",
    "#     chunk_size=1000,\n",
    "#     chunk_overlap=200,\n",
    "# )\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = text_splitter.split_documents(pages)\n",
    "for idx, text in enumerate(docs):\n",
    "    text.metadata[\"id\"] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='4. Dân tộc:   Kinh …………………………………….Quốc tịch:  Việt Nam  \\n5. Số CM ND:  034203001213  …cấp ngày :  2/1/2018  ...nơi cấp  Thành phố Thái Bình, Thái Bình  .  \\n6.Trường  học: đại học Bách Khoa Hà Nội  ................................ ................................ ........................    \\n7. Ngành học:  Khoa học máy tính ……… Lớp: IT1 -04 K66……..Mã SV:  20215335 ……   \\n8. Tình trạng hôn nhân:           Độc thân             Đã kết hôn  \\n9. Tên chồng/vợ:  ................................ ........  Ngày sinh: ................................ ................................ ....  \\n10. Nơi đăng ký hộ khẩu thường trú  (Quê quán) : 56, Lê Thánh Tông, Bồ Xuyên, Thái Bình ……  \\n11. Chỗ ở hiện tại:  32, 36, Lê Thanh Nghị, Cầu Dền, Hà Nội  ................................ ....................   \\n12. Số điện thoại: NR:………………………………..Di động:   0326920625  ...........................' metadata={'source': '../data/AT_PersonalInformation_Intern.pdf', 'page': 0, 'id': 1}\n"
     ]
    }
   ],
   "source": [
    "print(docs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\thực tập doanh nghiệp\\New folder\\.venv\\lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "No sentence-transformers model found with name VoVanPhuc/sup-SimCSE-VietNamese-phobert-base. Creating a new one with mean pooling.\n",
      "d:\\thực tập doanh nghiệp\\New folder\\.venv\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model =\"VoVanPhuc/sup-SimCSE-VietNamese-phobert-base\"\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name = model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = FAISS.from_documents(docs, embeddings)\n",
    "vectorstore.save_local(\"faiss_index\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = FAISS.load_local(\"faiss_index\", embeddings, allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "12. Số điện thoại: NR:………………………………..Di động:   0326920625  ...........................   \n",
      "13. E-mail:   Duy.PT215335@sis.hust.edu.vn  ................................ ................................ ..............   \n",
      "14. Vị trí  :  Thực tập sinh …… ………. ..Dự án :  Nghiên cứu và xây dựng ứng dụng dựa trên \n",
      "Open CV, AI, Deep Learnin g \n",
      "15. Ngày bắt đầu :  10/6/2024 ………………………………..  ................................ ...................   \n",
      "16. Quy định về bảo mật thông tin: ( điền theo mẫu riêng của công ty ) \n",
      "18. Tên máy tính  (nên đặt tên máy mang tính gợi nhớ, vd: TaiND ):  pduy395  ...............................    \n",
      "19. Địa chỉ MAC mạng LAN : 08-8F-C3-0B-9F-67 …Địa chỉ MAC WIFI:  14-85-7F-5C-53-00. \n",
      " Hà Nội, Ngày 10 tháng 6 năm 2024  \n",
      "  \n",
      " Người khai  Phụ trách trực tiếp   Phụ trách bộ phận  Phụ trách nhân sự  \n",
      "Duy \n",
      "Phạm Tiến Duy\n",
      "Metadata: {'source': '../data/AT_PersonalInformation_Intern.pdf', 'page': 0, 'id': 2}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "ARROW  TECHNOLOGIES CO., LTD  \n",
      "18F, VTC online tower , 18 Tam Trinh , Ha Noi  \n",
      "www.arrow -tech.vn\n",
      "Metadata: {'source': '../data/AT_PersonalInformation_Intern.pdf', 'page': 1, 'id': 3}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "4. Dân tộc:   Kinh …………………………………….Quốc tịch:  Việt Nam  \n",
      "5. Số CM ND:  034203001213  …cấp ngày :  2/1/2018  ...nơi cấp  Thành phố Thái Bình, Thái Bình  .  \n",
      "6.Trường  học: đại học Bách Khoa Hà Nội  ................................ ................................ ........................    \n",
      "7. Ngành học:  Khoa học máy tính ……… Lớp: IT1 -04 K66……..Mã SV:  20215335 ……   \n",
      "8. Tình trạng hôn nhân:           Độc thân             Đã kết hôn  \n",
      "9. Tên chồng/vợ:  ................................ ........  Ngày sinh: ................................ ................................ ....  \n",
      "10. Nơi đăng ký hộ khẩu thường trú  (Quê quán) : 56, Lê Thánh Tông, Bồ Xuyên, Thái Bình ……  \n",
      "11. Chỗ ở hiện tại:  32, 36, Lê Thanh Nghị, Cầu Dền, Hà Nội  ................................ ....................   \n",
      "12. Số điện thoại: NR:………………………………..Di động:   0326920625  ...........................\n",
      "Metadata: {'source': '../data/AT_PersonalInformation_Intern.pdf', 'page': 0, 'id': 1}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 4:\n",
      "\n",
      "ARROW  TECHNOLOGIES CO., LTD  \n",
      "18F, VTC online tower , 18 Tam Trinh , Ha Noi  \n",
      "www.arrow -tech.vn   \n",
      " \n",
      " \n",
      "BẢN KHAI THÔNG TIN CÁ NHÂN  \n",
      " \n",
      "Các bạn Sinh viên  mới vào thực tập  tại công ty ARROW  TECHNOLOGIES  phải khai đầy đủ \n",
      "thông tin vào mẫu này sau đó ký xác nhận và gửi lại cho Bộ phận Nhân sự  (cả bản cứng và bản \n",
      "mềm ).  \n",
      " \n",
      "Xin vui lòng liên hệ vớ i trưởng nhóm phụ trách trực tiếp hoặc  Bộ phận Nhân sự  trong trường \n",
      "hợp cần hỗ trợ trong việc điền các thông tin vào mẫu này .   \n",
      " \n",
      " \n",
      "1. Họ và tên:   Phạm Tiến Duy  ................................ ................................ ................................ ...........   \n",
      "2. Ngày sinh:   19/12/2003  ..........................  . Nơi sinh :  Thành phố Thái Bình, Thái Bình  ...............   \n",
      "3. Giới tính:                           Nam                     Nữ \n",
      "4. Dân tộc:   Kinh …………………………………….Quốc tịch:  Việt Nam  \n",
      "5. Số CM ND:  034203001213  …cấp ngày :  2/1/2018  ...nơi cấp  Thành phố Thái Bình, Thái Bình  .\n",
      "Metadata: {'source': '../data/AT_PersonalInformation_Intern.pdf', 'page': 0, 'id': 0}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def pretty_print_docs(docs):\n",
    "    print(\n",
    "        f\"\\n{'-' * 100}\\n\".join(\n",
    "            [\n",
    "                f\"Document {i+1}:\\n\\n{d.page_content}\\nMetadata: {d.metadata}\"\n",
    "                for i, d in enumerate(docs)\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "retriever = vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 10})\n",
    "\n",
    "query = \"định nghĩa của mạng RNN\"\n",
    "docs = retriever.invoke(query)\n",
    "pretty_print_docs(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import CohereRerank\n",
    "\n",
    "# Create the retriever\n",
    "compressor = CohereRerank(cohere_api_key='1Ld9LQLqTkOc29ABj54VRHOfyONyp4mtYIfpy7m1', top_n=5)\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[283, 249, 275, 271, 289]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "compressed_docs = compression_retriever.invoke(\n",
    "    query\n",
    ")\n",
    "print([doc.metadata[\"id\"] for doc in compressed_docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pathlib\n",
    "import textwrap\n",
    "\n",
    "import google.generativeai as genai\n",
    "\n",
    "from IPython.display import display\n",
    "from IPython.display import Markdown\n",
    "\n",
    "\n",
    "def to_markdown(text):\n",
    "  text = text.replace('•', '  *')\n",
    "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or use `os.getenv('GOOGLE_API_KEY')` to fetch an environment variable.\n",
    "GOOGLE_API_KEY=\"AIzaSyCozqIzVfFdFfvJgmxAlN8g5ETeuyJkxUQ\"\n",
    "\n",
    "genai.configure(api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/gemini-1.0-pro\n",
      "models/gemini-1.0-pro-001\n",
      "models/gemini-1.0-pro-latest\n",
      "models/gemini-1.0-pro-vision-latest\n",
      "models/gemini-1.5-flash\n",
      "models/gemini-1.5-flash-001\n",
      "models/gemini-1.5-flash-latest\n",
      "models/gemini-1.5-pro\n",
      "models/gemini-1.5-pro-001\n",
      "models/gemini-1.5-pro-latest\n",
      "models/gemini-pro\n",
      "models/gemini-pro-vision\n"
     ]
    }
   ],
   "source": [
    "for m in genai.list_models():\n",
    "  if 'generateContent' in m.supported_generation_methods:\n",
    "    print(m.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel('gemini-1.5-pro-latest')\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "def generate_response(input_text):\n",
    "    doc = format_docs(compression_retriever.invoke(input_text))\n",
    "#\n",
    "    prompt_text = f\"\"\"\n",
    "        Bạn là trợ lý cho các nhiệm vụ trả lời câu hỏi.\n",
    "        Hãy trả lời câu hỏi dựa trên dữ liệu có trong đoạn ngữ cảnh\n",
    "        Hãy trả lời không biết nêu không có thông tin tron đoạn ngữ cảnh\n",
    "\n",
    "        đoạn ngữ cảnh: {doc}\n",
    "\n",
    "        câu hỏi: {input_text}\n",
    "\n",
    "        câu trả lời:\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "    response = model.generate_content(prompt_text)\n",
    "    return to_markdown(response.text).data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_response(\"địa chỉ người khai thông tin là\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "\n",
    "iface = gr.Interface(generate_response,\n",
    "                     inputs=\"textbox\",\n",
    "                     outputs=\"textbox\",\n",
    "                     title=\"Chatbot about Deep learning\",\n",
    "                     description=\"Enter your message and the chatbot will respond accordingly.\")\n",
    "iface.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.Chatbot(height=600)\n",
    "    msg = gr.Textbox()\n",
    "    clear = gr.ClearButton([msg, chatbot])\n",
    "\n",
    "    def respond(message, chat_history):\n",
    "        bot_message = generate_response(message)\n",
    "        chat_history.append((message, bot_message))\n",
    "        return \"\", chat_history\n",
    "\n",
    "    msg.submit(respond, [msg, chatbot], [msg, chatbot])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"d:\\thực tập doanh nghiệp\\New folder\\.venv\\lib\\site-packages\\gradio\\queueing.py\", line 541, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "  File \"d:\\thực tập doanh nghiệp\\New folder\\.venv\\lib\\site-packages\\gradio\\route_utils.py\", line 276, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"d:\\thực tập doanh nghiệp\\New folder\\.venv\\lib\\site-packages\\gradio\\blocks.py\", line 1928, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"d:\\thực tập doanh nghiệp\\New folder\\.venv\\lib\\site-packages\\gradio\\blocks.py\", line 1514, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"d:\\thực tập doanh nghiệp\\New folder\\.venv\\lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "  File \"d:\\thực tập doanh nghiệp\\New folder\\.venv\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2177, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"d:\\thực tập doanh nghiệp\\New folder\\.venv\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 859, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"d:\\thực tập doanh nghiệp\\New folder\\.venv\\lib\\site-packages\\gradio\\utils.py\", line 833, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"C:\\Users\\pduy3\\AppData\\Local\\Temp\\ipykernel_11224\\653875721.py\", line 9, in respond\n",
      "    bot_message = generate_response(message)\n",
      "  File \"C:\\Users\\pduy3\\AppData\\Local\\Temp\\ipykernel_11224\\1155223890.py\", line 23, in generate_response\n",
      "    return to_markdown(response.text).data\n",
      "  File \"d:\\thực tập doanh nghiệp\\New folder\\.venv\\lib\\site-packages\\google\\generativeai\\types\\generation_types.py\", line 412, in text\n",
      "    raise ValueError(\n",
      "ValueError: Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. Please check the `candidate.safety_ratings` to determine if the response was blocked.\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\thực tập doanh nghiệp\\New folder\\.venv\\lib\\site-packages\\gradio\\queueing.py\", line 541, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "  File \"d:\\thực tập doanh nghiệp\\New folder\\.venv\\lib\\site-packages\\gradio\\route_utils.py\", line 276, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"d:\\thực tập doanh nghiệp\\New folder\\.venv\\lib\\site-packages\\gradio\\blocks.py\", line 1928, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"d:\\thực tập doanh nghiệp\\New folder\\.venv\\lib\\site-packages\\gradio\\blocks.py\", line 1514, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"d:\\thực tập doanh nghiệp\\New folder\\.venv\\lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "  File \"d:\\thực tập doanh nghiệp\\New folder\\.venv\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2177, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"d:\\thực tập doanh nghiệp\\New folder\\.venv\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 859, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"d:\\thực tập doanh nghiệp\\New folder\\.venv\\lib\\site-packages\\gradio\\utils.py\", line 833, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"C:\\Users\\pduy3\\AppData\\Local\\Temp\\ipykernel_11224\\653875721.py\", line 9, in respond\n",
      "    bot_message = generate_response(message)\n",
      "  File \"C:\\Users\\pduy3\\AppData\\Local\\Temp\\ipykernel_11224\\1155223890.py\", line 23, in generate_response\n",
      "    return to_markdown(response.text).data\n",
      "  File \"d:\\thực tập doanh nghiệp\\New folder\\.venv\\lib\\site-packages\\google\\generativeai\\types\\generation_types.py\", line 412, in text\n",
      "    raise ValueError(\n",
      "ValueError: Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. Please check the `candidate.safety_ratings` to determine if the response was blocked.\n"
     ]
    }
   ],
   "source": [
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
